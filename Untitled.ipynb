{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be92eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from typing import List, Optional\n",
    "import wget\n",
    "\n",
    "from pyhealth.datasets import MIMIC3Dataset\n",
    "\n",
    "from pyhealth.tasks import mortality_prediction_mimic3_fn\n",
    "\n",
    "MIMIC_PATH = \"/Users/xuzhentao/Desktop/SAnD/MIMIC3\"\n",
    "\n",
    "\n",
    "def get_mimic_iii(\n",
    "        tables: Optional[List[str]] = [\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\", \"PRESCRIPTIONS\"],\n",
    "        code_mapping: Optional[List[str]] = {\"NDC\": (\"ATC\", {\"target_kwargs\": {\"level\": 3}})}\n",
    ") -> MIMIC3Dataset:\n",
    "    mimic3base = MIMIC3Dataset(\n",
    "        root=MIMIC_PATH,\n",
    "        tables=tables,\n",
    "        code_mapping=code_mapping,\n",
    "    )\n",
    "    return mimic3base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee283d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_mimic_iii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = dataset.set_task(mortality_prediction_mimic3_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the stats\n",
    "new_dataset.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf0e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from typing import *\n",
    "\n",
    "\n",
    "patient_procedure:Dict[str, List[str]] = dict()\n",
    "patient_label:Dict[str, int] = dict()\n",
    "    \n",
    "for i in range(len(new_dataset.samples)):\n",
    "    sample = new_dataset.samples[i]\n",
    "    patient_id = sample['patient_id']\n",
    "    visit_id = sample['visit_id']\n",
    "    procedures = sample['procedures']\n",
    "    if patient_id not in patient_procedure:\n",
    "        patient_procedure[patient_id] = []\n",
    "    if patient_id not in patient_label:\n",
    "        patient_label[patient_id] = None\n",
    "    patient_procedure[patient_id].append(procedures[0])\n",
    "    patient_label[patient_id] = sample['label']\n",
    "\n",
    "\n",
    "print(patient_label)\n",
    "print(patient_procedure)\n",
    "\n",
    "patients = sorted(list(patient_label.keys()))\n",
    "label = [patient_label[p] for p in patients]\n",
    "procedures = [patient_procedure[p] for p in patients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38956dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_codes = []\n",
    "\n",
    "'''\n",
    "Append all codes that appears more than 50 times in freq_codes list.\n",
    "'''\n",
    "\n",
    "seqs = procedures\n",
    "\n",
    "cnt_dict = {}\n",
    "for i in range(len(seqs)):\n",
    "    for j in range(len(seqs[i])):\n",
    "        for each_code in seqs[i][j]:\n",
    "            if each_code not in cnt_dict:\n",
    "                cnt_dict[each_code] = 1\n",
    "            else:\n",
    "                cnt_dict[each_code] += 1\n",
    "\n",
    "for each_code in cnt_dict:\n",
    "    if cnt_dict[each_code] >= 100:\n",
    "        freq_codes.append(each_code)\n",
    "        \n",
    "print(freq_codes)\n",
    "print(len(freq_codes))\n",
    "\n",
    "code2idx = {code: idx for idx, code in enumerate(freq_codes)}\n",
    "print(code2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seqs, hfs):\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: Store `seqs`. to `self.x` and `hfs` to `self.y`.\n",
    "        \n",
    "        Note that you DO NOT need to covert them to tensor as we will do this later.\n",
    "        Do NOT permute the data.\n",
    "        \"\"\"\n",
    "        self.x = seqs\n",
    "        self.y = hfs\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: Return the number of samples (i.e. patients).\n",
    "        \"\"\"\n",
    "        \n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: Generates one sample of data.\n",
    "        \n",
    "        Note that you DO NOT need to covert them to tensor as we will do this later.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "\n",
    "dataset = CustomDataset(procedures, label)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Collate the the list of samples into batches. For each patient, you need to pad the diagnosis\n",
    "        sequences to the sample shape (max # visits, len(freq_codes)). The padding infomation\n",
    "        is stored in `mask`.\n",
    "    \n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patiens, max # visits, len(freq_codes)) of type torch.float\n",
    "        masks: a tensor of shape (# patiens, max # visits) of type torch.bool\n",
    "        y: a tensor of shape (# patiens) of type torch.float\n",
    "        \n",
    "    Note that you can obtains the list of diagnosis codes and the list of hf labels\n",
    "        using: `sequences, labels = zip(*data)`\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    max_num_visits = max(num_visits)\n",
    "    \n",
    "    x = torch.zeros((num_patients, max_num_visits, len(freq_codes)), dtype=torch.float)    \n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            for code in visit:\n",
    "                \"\"\"\n",
    "                TODO: 1. check if code is in freq_codes;\n",
    "                      2. obtain the code index using code2idx;\n",
    "                      3. set the correspoindg element in x to 1.\n",
    "                \"\"\"\n",
    "                if code in freq_codes:\n",
    "                    x[i_patient, j_visit, code2idx[code]] = 1\n",
    "                \n",
    "                y[i_patient] = labels[i_patient]\n",
    "                    \n",
    "                    \n",
    "                \n",
    "    \n",
    "    masks = torch.sum(x, dim=-1) > 0\n",
    "    \n",
    "    return x, masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce72fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=100000, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x, masks, y = next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(torch.randn(512, 256, 23) .shape)\n",
    "print(torch.randint(0, 9, (512,)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d934189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from core.model import SAnD\n",
    "from utils.trainer import NeuralNetworkClassifier\n",
    "\n",
    "# x_train = torch.randn(512, 256, 23)  # [N, seq_len, features]\n",
    "# x_val = torch.randn(128, 256, 23)  # [N, seq_len, features]\n",
    "# x_test = torch.randn(512, 256, 23)  # [N, seq_len, features]\n",
    "\n",
    "# y_train = torch.randint(0, 9, (512,))\n",
    "# y_val = torch.randint(0, 9, (128,))\n",
    "# y_test = torch.randint(0, 9, (512,))\n",
    "\n",
    "x_train = x_val = x_test = x\n",
    "y_train = y_val = y_test = y\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "val_ds = TensorDataset(x_val, y_val)\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128)\n",
    "val_loader = DataLoader(val_ds, batch_size=128)\n",
    "test_loader = DataLoader(test_ds, batch_size=128)\n",
    "\n",
    "in_feature = 73\n",
    "seq_len = 28\n",
    "n_heads = 2\n",
    "factor = 32\n",
    "num_class = 2\n",
    "num_layers = 6\n",
    "\n",
    "clf = NeuralNetworkClassifier(\n",
    "    SAnD(in_feature, seq_len, n_heads, factor, num_class, num_layers),\n",
    "    nn.CrossEntropyLoss(),\n",
    "    optim.Adam, optimizer_config={\"lr\": 1e-5, \"betas\": (0.9, 0.98), \"eps\": 4e-09, \"weight_decay\": 5e-4},\n",
    "    experiment=Experiment(\"<TODO>\", project_name=\"sand_demo_testing\")\n",
    "    # Note: This is Zhentao's personal key but OK for sharing here.\n",
    ")\n",
    "\n",
    "# training network\n",
    "clf.fit(\n",
    "    {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": val_loader\n",
    "    },\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# evaluating\n",
    "clf.evaluate(test_loader)\n",
    "\n",
    "# save\n",
    "clf.save_to_file(\"save_params/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7af8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
